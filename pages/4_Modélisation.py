# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""

import streamlit as st
import pandas as pd
pd.set_option('display.max_colwidth', None)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder,MinMaxScaler,OrdinalEncoder,RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_selector
from sklearn.pipeline import Pipeline

from sklearn.linear_model import Ridge
from xgboost import XGBRegressor

from sklearn.metrics import mean_squared_error
from sklearn.inspection import permutation_importance

from PIL import Image


#Configurer l'affichage en mode Wide
st.set_page_config(
    layout="wide",
    initial_sidebar_state="expanded",
    page_title = "Temps de R√©ponse de la Brigade des Pompiers de Londres")


## Supprimer l'espace vide en haut de la page
st.markdown("""
<style>

.block-container
{
    padding-top: 1rem;
    padding-bottom: 5rem;
    margin-top: 0rem;
}

</style>
""", unsafe_allow_html=True)

st.set_option('deprecation.showPyplotGlobalUse', False)

@st.cache_data
def load_data(file):
    data = pd.read_csv(file)
    return data

def add_logo():
    st.markdown(
        """
        <style>
            [data-testid="stSidebarNav"] {
                background-image: url(https://www.kenistonha.co.uk/wp-content/uploads/2017/06/London-fire-brigade-2-992x561.png);
                background-repeat: no-repeat;
                background-size: 250px 125px;
                padding-top: 80px;
                background-position: 40px 20px;
                margin-top: 4px;

            }
        """,
        unsafe_allow_html=True,
    )


def main():
    
    add_logo()

    st.header("üèãÔ∏è Mod√©lisation")
    st.write("L'objectif de cette √©tape est de d√©velopper un mod√®le de Machine Learning pour r√©pondre √† l'objectif initial.")
    
    
    df = load_data("df_EnrichiModelisation.csv")

    all_years = df["YearOfTheCall"].unique().tolist()
    
    min_year = min(all_years)
    max_year = max(all_years)
    
    expander = st.sidebar.expander("**CHOISIR UNE P√âRIODE**",expanded=False)
    start_year, end_year = expander.slider("Date of Call", min_year, max_year, (2022, 2022))
    
    df = df[(df['YearOfTheCall'] >= start_year) & (df['YearOfTheCall'] <= end_year)]

    st.subheader(" ")
    st.subheader("0. Choix d'un mod√®le")
    model_type = st.selectbox("Choisir un mod√®le :", ['Ridge','XGBRegressor'])
    
    if model_type == "XGBRegressor" :
        df = df[["IncidentGroupType", "BoroughName","WardName","HourOfCall","PropertyType","DeployedFromStationName","Distance","NumStationsWithPumpsAttending",
                 "LatitudeIncident","LongitudeIncident","LatitudeStation","LongitudeStation","SecondPumpArrivingDeployedFromStation","AttendanceTime"]]

        with st.expander("Explications", expanded=True):
                st.markdown("""
                    Le XGBRegressor est une m√©thode de pr√©diction bas√©e sur le principe du **gradient boosting**. 
                    
                    C'est comme si vous aviez une √©quipe de chercheurs (les arbres de d√©cision) qui travaillent ensemble pour r√©soudre un probl√®me complexe (la pr√©diction). Chaque chercheur apporte sa propre expertise et ses propres id√©es, et ensemble, ils arrivent √† une solution plus pr√©cise et plus robuste qu'un seul chercheur ne pourrait le faire.
                    
                    Dans le cas du XGBRegressor, chaque "chercheur" est un arbre de d√©cision. Le mod√®le commence par un seul arbre, puis ajoute progressivement d'autres arbres pour corriger les erreurs faites par les arbres pr√©c√©dents. C'est ce qu'on appelle le gradient boosting.
                    
                    Le XGBRegressor est particuli√®rement efficace lorsque vous avez beaucoup de donn√©es et de nombreuses variables. Cependant, il faut noter que son temps de traitement est g√©n√©ralement plus long compar√© au mod√®le Ridge.
                    """)
                        
    else :
        
        df = df[["Distance","DeployedFromStationName","WardName","LongitudeStation","LongitudeIncident","ResourceCode","BoroughName","WeekOfTheCall","MonthOfTheCall",
    "Region","MomentOfTheDay","PropertyType","AttendanceTime"]]

        with st.expander("Explications", expanded=True):
            st.markdown("""
                La r√©gression Ridge est une m√©thode utilis√©e en statistiques pour pr√©dire des donn√©es. 
                
                Elle fonctionne un peu comme une recette de cuisine : on a plusieurs ingr√©dients (les donn√©es d'entr√©e) et on veut obtenir un plat d√©licieux (la pr√©diction). 
                
                Cependant, parfois, certains ingr√©dients peuvent prendre le dessus et g√¢cher le plat. Pour √©viter cela, la r√©gression Ridge p√©nalise les ingr√©dients trop dominants, c'est-√†-dire qu'elle r√©duit leur importance dans la recette. 
                
                Le but est d'obtenir un plat (une pr√©diction) qui est un bon √©quilibre de tous les ingr√©dients (donn√©es d'entr√©e), plut√¥t que d'√™tre domin√© par un ou deux ingr√©dients. """)
 

    # S√©paration des features (X) et de la variable cible (y)
    X = df.drop('AttendanceTime', axis=1)
    y = df['AttendanceTime']
    
    # S√©paration des donn√©es d'entra√Ænement et de test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)
    
    st.subheader(" ")
    
########################################################################################################################################################################################################################## 
    st.subheader("1. Pr√©-traitement des donn√©es")
    
    my_expander = st.sidebar.expander("**PR√âTRAITER LES DONN√âES**",expanded=False)
    my_expander2 = st.sidebar.expander("**R√âGLER LES HYPERPARAM√àTRES**",expanded=True)
    
    encoder_type = my_expander.selectbox("Type d'encodeur", ['OneHotEncoder','OrdinalEncoder'])
    
    scaler_type = my_expander.selectbox('Type de normalisateur', ['StandardScaler','MinMaxScaler','RobustScaler'])
    
    st.markdown(f"<div style='text-align: left; color: black; background-color: #ff9800; padding: 10px; border-radius: 5px;'>‚ö†Ô∏è Sur la p√©riode de {start_year} √† {end_year}, vous avez pr√©-trait√© les donn√©es avec un {encoder_type} et un {scaler_type}.</div>", unsafe_allow_html=True)
    st.subheader(" ")
    
    
    numeric_features = make_column_selector(dtype_include=np.number)
    categorical_features = make_column_selector(dtype_exclude=np.number)
    
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),
        ('scaler', eval(scaler_type)())
    ])
    

    if encoder_type == 'OneHotEncoder':
        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing')),
            ('encoder', eval(encoder_type)(drop='first', sparse_output=True, handle_unknown='ignore'))
        ])
    
    else:
        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing')),
            ('encoder', eval(encoder_type)(handle_unknown='use_encoded_value', unknown_value=-1))
        ])
    

    preprocessor = ColumnTransformer(
        transformers=[
            ('categorical', categorical_transformer, categorical_features),
            ('numeric', numeric_transformer, numeric_features) 
        ])
    

    array_transformed = preprocessor.fit_transform(X)

    feature_names = preprocessor.get_feature_names_out()

    if hasattr(array_transformed, "toarray"):

        df_transformed = pd.DataFrame(array_transformed.toarray(), columns=feature_names)
    
    else:

        df_transformed = pd.DataFrame(array_transformed, columns=feature_names)
    
    st.dataframe(df_transformed.head(7))

    with st.expander("Explications", expanded=True):
            st.markdown("""
                Les algorithmes de machine learning ont souvent des exigences sp√©cifiques sur le format des donn√©es. 
                Par exemple, ils peuvent n√©cessiter que toutes les variables soient num√©riques. Le pr√©traitement permet de transformer les donn√©es pour qu‚Äôelles soient compatibles avec ces exigences.
                
                ######   
                
                ##### Types d‚Äôencodeurs
                Ordinal Encoder : 
                - C‚Äôest donner un num√©ro √† chaque √©l√©ment d‚Äôune liste. Par exemple, dans une liste de fruits, on pourrait dire que la Pomme est le num√©ro 1, la Banane le num√©ro 2.
                    
                One-Hot Encoder :
                - Avec ce type d'encodeur on cr√©e une colonne pour chaque fruit. Si le fruit est pr√©sent, on met un 1 dans cette colonne, s'il n‚Äôest pas pr√©sent, on met un 0. 
                - Par exemple, si vous avez "Pomme", on aurait : Pomme (1) Banane (0) soit 10.

                ######   
                
                ##### Type de normalisateurs
                MinMaxScaler :
                - Imaginez que vous avez une √©chelle de 1 √† 100, mais vos donn√©es sont comprises entre 200 et 300. Le MinMaxScaler va simplement "recalibrer" vos donn√©es pour qu‚Äôelles soient comprises entre 1 et 100.
                
                StandardScaler :
                - Imaginez que vous mesurez la taille de personnes en centim√®tres et en pouces. Il serait difficile de les comparer directement car elles sont sur des √©chelles diff√©rentes. Le StandardScaler convertit toutes les mesures dans une ‚Äúlangue commune‚Äù (comme convertir toutes les mesures en centim√®tres), ce qui rend la comparaison plus facile.

                RobustScaler :
                - Imaginez que vous mesurez le poids de plusieurs objets, dont un √©l√©phant. Le poids de l‚Äô√©l√©phant est une valeur aberrante et peut fausser vos r√©sultats. Le RobustScaler r√©duit l‚Äôimpact de ces valeurs aberrantes en se concentrant sur la majorit√© des donn√©es, ce qui donne une meilleure repr√©sentation g√©n√©rale.
              """)
    
########################################################################################################################################################################################################################## 
    st.subheader("2. Performances du mod√®le")
    st.subheader(" ")
    
    
    if model_type == 'XGBRegressor':
       colsample_bytree = my_expander2.slider('Colsample bytree', min_value=0.1, max_value=1.0, value=0.7746831999163204)
       learning_rate = my_expander2.slider('Learning rate', min_value=0.1, max_value=1.0, value=0.0624207548570334)
       max_depth = my_expander2.slider('Max Depth', min_value=1, max_value=12, value=1)
       min_child_weight = my_expander2.slider('Min child weight', min_value=1, max_value=5, value=1)
       n_estimators = my_expander2.slider('N_estimators', min_value=100, max_value=1200, value=300)

       model = XGBRegressor(colsample_bytree =colsample_bytree,  
       learning_rate = learning_rate,  
       max_depth = max_depth,  
       min_child_weight = min_child_weight, 
       n_estimators = n_estimators, 
       random_state=0)
    
    else:
        alpha = my_expander2.slider('Alpha', min_value=1.0, max_value=50.0, value=9.372353071731432)
        solver = my_expander2.selectbox('Solver', ['auto', 'lsqr', 'sparse_cg', 'sag'])
        fit_intercept = my_expander2.checkbox('Inclure l\'interception', value=True)
        model = Ridge(alpha=alpha, solver=solver, fit_intercept=fit_intercept)


    model_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('estimator', model)
    ])
    
    # Entra√Ænement du mod√®le sur les donn√©es d'entra√Ænement
    model_pipeline.fit(X_train, y_train)
    
    # Pr√©diction sur les donn√©es d'entra√Ænement et de test
    y_train_pred = model_pipeline.predict(X_train)
    y_test_pred = model_pipeline.predict(X_test)
    
    # Calcul des m√©triques d'√©valuation
    Train_score = round(model_pipeline.score(X_train, y_train), 2)
    Train_RMSE= round(mean_squared_error(y_train, y_train_pred, squared=False), 3)
    Test_score= round(model_pipeline .score(X_test, y_test), 2)
    Test_RMSE= round(mean_squared_error(y_test, y_test_pred, squared=False), 3)
    
    data_score_after = pd.DataFrame({
    'Model': [str(model_pipeline["estimator"]).split("(")[0]],
    'R¬≤ Train': [Train_score],
    'R¬≤ Test': [Test_score],
    'Train RMSE': [Train_RMSE],
    'Test RMSE': [Test_RMSE] })
    
    st.write(data_score_after)
    
    with st.expander("Explications", expanded=False):
        st.markdown("""
        #### M√©triques d'√©valuation
        Nous avons utilis√© 2 m√©triques pour √©valuer les performances des mod√®les :
        
        1. **Coefficient de d√©termination (R¬≤)** : 
            - Indique la proportion de la variance de la variable cible qui est pr√©visible √† partir des variables ind√©pendantes. 
            - Il varie de 0 √† 1, o√π 1 indique que le mod√®le explique parfaitement la variabilit√© des donn√©es.
        
        ######   
        
        2. **Erreur quadratique moyenne racine (RMSE)** : 
            - C'est la racine carr√©e de la moyenne des carr√©s des diff√©rences entre les valeurs pr√©dites et les valeurs r√©elles. 
            - Elle a la m√™me unit√© que la variable cible, ce qui la rend facilement interpr√©table. 
            - Elle varie de 0 √† 1, o√π 1 indique que le mod√®le explique parfaitement la variabilit√© des donn√©es.
            
        Ces m√©triques sont calcul√©es sur les donn√©es d'entra√Ænement (Train) et les donn√©es de test (Test).
        
        ######   

        #### Risque d'overfitting
        Il est important de noter que lors de l‚Äô√©valuation d'un mod√®le, nous devons √™tre conscient du risque d‚Äôoverfitting. 
        L‚Äôoverfitting se produit lorsque le mod√®le apprend ‚Äúpar c≈ìur‚Äù les donn√©es d‚Äôentra√Ænement, au point qu‚Äôil ne peut pas g√©n√©raliser efficacement face √† de nouvelles donn√©es. 
        Un mod√®le overfitted peut sembler offrir une pr√©cision √©lev√©e lorsqu‚Äôil est appliqu√© aux donn√©es d‚Äôentra√Ænement (R¬≤ Train √©lev√©), 
        mais sa performance sera amoindrie en production sur de nouvelles donn√©es (R¬≤ Test faible). 
        Par cons√©quent, il est crucial de surveiller ces 2 m√©triques.
        """)
    
    st.subheader(" ")
    
########################################################################################################################################################################################################################## 
    st.subheader("3. Visualisation graphique des pr√©dictions")
    
    
    # S√©lection de la plage de donn√©es
    d√©but, fin = st.slider('S√©lectionnez une plage de donn√©es', min_value=0, max_value=500, value=(0, 50))
    x_ax = range(len(y_test))[d√©but:fin]
    
    # Cr√©ation du graphique
    fig, ax = plt.subplots(figsize=(16,6.5))
    
    ax.plot(x_ax, y_test[d√©but:fin], label="original", c="blue", linewidth=1, marker="o", markersize=6)
    ax.plot(x_ax, y_test_pred[d√©but:fin], label="pr√©diction", c="orange", linewidth=2, marker="o", markersize=6)
    
    ax.set_title("Pr√©dictions avec le mod√®le : " + str(model_pipeline.named_steps['estimator']).split("(")[0], fontsize=14)
    ax.legend(loc='best')
    
    ax.grid(visible=True, linewidth=0.5)
    
    st.pyplot(fig)

    def convert_to_min_sec(value):
        minutes = int(abs(value))
        seconds = int((abs(value) - minutes) * 60)
        return f"{'-' if value < 0 else ''}{minutes} min {seconds} sec"
    
    st.title(" ")

########################################################################################################################################################################################################################## 
    st.subheader("4. Analyse des r√©sidus")
    st.write(" ")
    
    # Pr√©diction du mod√®le
    y_test_pred_residu = model_pipeline.predict(X_test)
    
    # Calcul des r√©sidus
    residus = y_test_pred_residu - y_test
    
    # Calcul des quantiles
    quantiles = np.quantile(residus, [0.10, 0.90])
    
    sns.relplot(x=y_test, y=residus, alpha=0.05, height=5, aspect=50/22)
    plt.plot([0, y_test.max()], [0, 0], 'r--')
    plt.plot([0, y_test.max()], [quantiles[0], quantiles[0]], 'y--', label="80% des r√©sidus pr√©sents dans cet interquartile")
    plt.plot([0, y_test.max()], [quantiles[1], quantiles[1]], 'y--')
    
    # Ajout des annotations
    plt.text(y_test.max(), quantiles[0], f'{quantiles[0]:.2f}', verticalalignment='bottom', horizontalalignment='right')
    plt.text(y_test.max(), quantiles[1], f'{quantiles[1]:.2f}', verticalalignment='bottom', horizontalalignment='right')
    
    plt.xlabel("y_test")
    plt.ylabel("test_r√©sidus")
    plt.legend()
    st.pyplot()
    
    with st.expander("Explications",expanded=True):
        st.write("""
        Ce graphique est une repr√©sentation visuelle de l'analyse des r√©sidus. Voici quelques points cl√©s :
        - La concentration dense de points bleus indique la distribution des r√©sidus.
        - La ligne pointill√©e rouge repr√©sente le point de r√©f√©rence o√π il n‚Äôy a aucun r√©sidu
        - Les lignes jaunes repr√©sentent l'interquatile de 80% des r√©sidus 
        """)
        st.write(f"""Avec votre mod√®le, dans 80% des cas, l'erreur des pr√©dictions se situe entre {convert_to_min_sec(quantiles[0])} et {convert_to_min_sec(quantiles[1])}.
                 """)
        
    st.title(" ")

########################################################################################################################################################################################################################## 
    st.subheader("5. Interpr√©tabilit√© de votre mod√®le - Features importances")
    st.write(" ")
    
    
    # Calcul des importances des variables explicatives √† l'aide de la permutation
    feature_importances = permutation_importance(model_pipeline, X_test, y_test, n_repeats=1, random_state=42,scoring="r2")
    
    # Cr√©ation d'un DataFrame avec les noms des variables explicatives et leurs importances
    importances_df = pd.DataFrame({
        "Features": X.columns,
        "Importance": feature_importances.importances_mean
    })
    
    # Tri des variables explicatives par ordre d'importance croissante
    importances_df = importances_df.sort_values(by="Importance", ascending=True).tail(10)
    
    # Trac√© d'un graphique √† barres horizontales
    fig, ax = plt.subplots(figsize=(16,8))
    plt.grid(visible=True, linewidth=0.5)
    plt.barh(y=importances_df["Features"], width=importances_df["Importance"], color="skyblue")
    plt.xlabel("Average impact on model output")
    plt.ylabel("Features")
    
    # Augmentation de la taille des √©tiquettes des axes
    plt.tick_params(axis='both', which='major', labelsize=14)
    plt.xlabel("Average impact on model output", fontsize=14)
    plt.ylabel("Features", fontsize=14)
    plt.title(str(model_pipeline["estimator"]).split("(")[0], fontsize=16)
    
    st.pyplot(plt)
    with st.expander("Explications",expanded=True):
        st.write("""
        Ce graphique illustre comment les diff√©rentes variables affectent les pr√©dictions du mod√®le. Plus la barre est longue, plus l‚Äôimpact de cette caract√©ristique est important. 
        
        Vous pouvez y voir les dix variables les plus influentes et leur effet sur les pr√©dictions.
        """)

    st.title(" ")
    st.write("---")
    
########################################################################################################################################################################################################################## 
    st.subheader("6. [Mod√®le retenu] - XGBRegressor")
    st.write("Entra√Ænement sur les donn√©es de 2015 √† 2022")
    
    st.write(" ")
    st.write("Pr√©-traitement des donn√©es : ")
    preprocessing= {
    "Type d'encoder": "OneHotEncoder",
    'Type de normalisateur': "StandardScaler"}
    df_preprocessing = pd.DataFrame(list(preprocessing.items()), columns=['Param√®tres', 'Valeurs'])
    st.dataframe(df_preprocessing)
    
    st.write(" ")
    st.write("R√©glage des hyperparam√®tres :")
    hyperparameters = {
    'colsample_bytree': 0.7746831999163204,
    'learning_rate': 0.0624207548570334,
    'max_depth': 6,
    'min_child_weight': 1,
    'n_estimators': 685}
    
    df_hyperparameters = pd.DataFrame(list(hyperparameters.items()), columns=['Hyperparam√®tres', 'Valeurs'])
    st.dataframe(df_hyperparameters)
    
    st.write("")
    st.write("Performances de notre mod√®le : ")
    score = pd.DataFrame([ 0.53, 0.5, 1.27, 1.32], index=['R¬≤ Train','R¬≤ Test', 'RMSE Train', 'RMSE Test']).T
    st.dataframe(score)
    st.write("")
    
    st.write("Features Importances :")
    image_features = Image.open('model_featuresImportances.png')
    st.image(image_features,use_column_width=True)
    with st.expander("Explications",expanded=True):
         st.write("""
                Quelques points cl√©s :
                - Distance : C‚Äôest la variable qui a le plus grand impact sur le mod√®le.
                - DeployedFromStationName et WardName : Ces deux variables ont √©galement un impact significatif sur le mod√®le, bien que moins que "Distance".
                - Les autres variables comme LongitudeIncident, LatitudeIncident, HourOfCall, etc., ont un impact moindre sur le mod√®le.
                """)
    st.header("")
    
    st.write("Analyse des r√©sidus :")
    image_residus = Image.open('Analyse_r√©sidus.png')
    st.image(image_residus,use_column_width=True)
    with st.expander("Explications",expanded=True):
         st.write("""
         Dans 80% des cas, l'erreur des pr√©dictions de notre mod√®le se situe entre -1 min 28 sec et 1 min 22 sec. 
         
         Cela signifie que lorsque le mod√®le pr√©dit 6 minutes, il existe une probabilit√© de 80 % que la valeur r√©elle se situe entre 4 minutes 38 secondes et 7 minutes 28 secondes.
        """)  
    st.header("")
    
    st.write("Interpr√©tabilit√© globale (impact des variables sur plusieurs pr√©dictions) :")
    image_shap = Image.open('model_Shap.png')
    st.image(image_shap,use_column_width=True)
    with st.expander("Explications",expanded=True):
         st.write("""
             Ce graphique SHAP illustre comment les diff√©rentes variables influencent les pr√©dictions d‚Äôun mod√®le. 
             Les points rouges correspondent √† des valeurs √©lev√©es de la variable, tandis que les points bleus correspondent √† des valeurs basses. 
    
             Voici ce que nous pouvons d√©duire de notre mod√®le :
              -  Distance : Plus la distance est courte, plus le temps de r√©ponse est rapide.
              - SecondPumpArrivingDeployedFromStation : Lorsque cette variable a la valeur "No Second pump deployed", le temps de r√©ponse est plus long que s‚Äôil y avait un second camion de pompiers d√©ploy√©.      
        """)  
        
if __name__ == "__main__":
    main()
